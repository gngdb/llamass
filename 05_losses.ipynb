{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a46aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d402b4fb",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> A selection of loss functions I've used with this dataset. These are research code with no guarantees of correctness or usefulness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85969a0c",
   "metadata": {},
   "source": [
    "## Axis-Angle Cosine Distance\n",
    "\n",
    "> Cosine similarity between rotation vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f86cd",
   "metadata": {},
   "source": [
    "This is probably not a correct distance metric for rotations. [This blog][belousov] makes an argument that there's only one correct distance metric for rotations and it's the angular distance between unit quaternions. But, it is quick to evaluate on rotation vectors.\n",
    "\n",
    "[belousov]: http://www.boris-belousov.net/2016/12/01/quat-dist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def aa_cosine(out, target):\n",
    "    if out.ndim == 2:\n",
    "        b, d = out.size()\n",
    "    elif out.ndim == 3:\n",
    "        b, f, d = out.size()\n",
    "        assert f == 1, f'{out.size()}'\n",
    "    j = d//3\n",
    "    out, target = out.view(b, j, 3), target.view(b, j, 3)\n",
    "    def theta(x, eps=1e-6):\n",
    "        return torch.sqrt(torch.clamp(torch.sum(x**2, 2, keepdims=True), eps, 2*math.pi))\n",
    "    theta_a = theta(out)\n",
    "    theta_b = theta(target)\n",
    "    cosine_sim = F.cosine_similarity(out, target, dim=2)\n",
    "    cosine_sim_loss = 1. - cosine_sim\n",
    "    cosine_angle_diff = 1. - torch.cos(theta_a - theta_b)\n",
    "    return torch.mean(cosine_sim_loss + cosine_angle_diff[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf2cc0",
   "metadata": {},
   "source": [
    "## VPoser\n",
    "\n",
    "> The loss function used by the VPoser VAE in the [SMPL-X][smplx] paper.\n",
    "\n",
    "[smplx]: https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/497/SMPL-X.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class GeodesicLossR(nn.Module):\n",
    "    def __init__(self, reduction='batchmean'):\n",
    "        super(geodesic_loss_R, self).__init__()\n",
    "\n",
    "        self.reduction = reduction\n",
    "        self.eps = 1e-6\n",
    "\n",
    "    # batch geodesic loss for rotation matrices\n",
    "    def bgdR(self,m1,m2):\n",
    "        batch = m1.shape[0]\n",
    "        m = torch.bmm(m1, m2.transpose(1, 2))  # batch*3*3\n",
    "\n",
    "        cos = (m[:, 0, 0] + m[:, 1, 1] + m[:, 2, 2] - 1) / 2\n",
    "        cos = torch.min(cos, m1.new(np.ones(batch)))\n",
    "        cos = torch.max(cos, m1.new(np.ones(batch)) * -1)\n",
    "\n",
    "        return torch.acos(cos)\n",
    "\n",
    "    def forward(self, ypred, ytrue):\n",
    "        theta = self.bgdR(ypred,ytrue)\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(theta)\n",
    "        if self.reduction == 'batchmean':\n",
    "            return torch.mean(torch.sum(theta, dim=theta.shape[1:]))\n",
    "        else:\n",
    "            return theta\n",
    "\n",
    "def vposer_likelihood(\n",
    "    self,\n",
    "    dec_out,\n",
    "    pose_target,\n",
    "    body_model,\n",
    "    loss_kl_wt=torch.tensor(0.005),\n",
    "    loss_rec_wt=torch.tensor(4),\n",
    "    loss_matrot_wt=torch.tensor(2),\n",
    "    loss_jtr_wt=torch.tensor(2),\n",
    "    callback=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Default settings for loss weights taken from:\n",
    "    https://github.com/nghorbani/human_body_prior/blob/master/src/human_body_prior/train/V02_05/V02_05.yaml\n",
    "    \"\"\"\n",
    "    l1_loss = torch.nn.L1Loss(reduction=\"mean\")\n",
    "    geodesic_loss = GeodesicLossR(reduction=\"mean\")\n",
    "\n",
    "    # cast decoder output to aa\n",
    "    bs, f, d = pose_target.size()\n",
    "    assert f == 1, 'assuming only one frame'\n",
    "    pose_target = pose_target.squeeze()\n",
    "    pose_out_matrot = dec_out.view(-1, 3, 3)\n",
    "    pose_out = matrot2aa(pose_out_matrot).view(bs, -1, 3)        \n",
    "\n",
    "    # Reconstruction loss - L1 on the output mesh\n",
    "    with torch.no_grad():\n",
    "        bm_orig = body_model(pose_body=pose_target)\n",
    "    bm_rec = body_model(pose_body=pose_out.contiguous().view(bs, -1))\n",
    "    v2v = l1_loss(bm_rec.v, bm_orig.v)\n",
    "\n",
    "    # Geodesic loss between rotation matrices\n",
    "    matrot_loss = loss_matrot_wt * geodesic_loss(\n",
    "        pose_out_matrot, aa2matrot(pose_target.view(-1, 3))\n",
    "    )\n",
    "    # L1 Loss on joint positions\n",
    "    jtr_loss = l1_loss(bm_rec.Jtr, bm_orig.Jtr)\n",
    "\n",
    "    # apply weights to make weighted loss\n",
    "    weighted_loss = (\n",
    "        loss_matrot_wt * matrot_loss + loss_rec_wt * v2v + loss_jtr_wt * jtr_loss\n",
    "    )\n",
    "\n",
    "    # log results\n",
    "    with torch.no_grad():\n",
    "        unweighted_loss = matrot_loss + v2v + jtr_loss\n",
    "        if callback is not None:\n",
    "            callback(all_univariate_tensors_in(locals()))\n",
    "\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba193b99",
   "metadata": {},
   "source": [
    "## Discretized Euler Angles\n",
    "\n",
    "> Intuitively, an ADC applied to Euler angles. Allows use of a NLL loss, which is can be useful for training a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def discretize(x, nquant, eps=1e-6, dither=False, zero_centered=True):\n",
    "    if zero_centered:\n",
    "        x = x + math.pi\n",
    "    m = math.pi*2\n",
    "    assert x.max() < m\n",
    "    x = x/m # scale to between zero and 1\n",
    "    x = x*nquant\n",
    "    if dither:\n",
    "        d = 2.*(torch.rand_like(x)-0.5)\n",
    "        x = torch.clamp(x+d, 0, nquant-eps)\n",
    "    return torch.floor(x).long() # bin account to nquant levels\n",
    "\n",
    "class DiscretizedEulerLoss(nn.Module):\n",
    "    def __init__(self, nquant, dither=False, zero_centered=True):\n",
    "        super().__init__()\n",
    "        self.nquant, self.dither, self.zero_centered = nquant, dither, zero_centered\n",
    "\n",
    "    def forward(self, out, target):\n",
    "        assert out.size(-1) == self.nquant, f'trailing dimension should hold logits {out.size()}'\n",
    "        target = discretize(target, self.nquant, dither=self.dither, zero_centered=self.zero_centered)\n",
    "        return F.nll_loss(out.view(-1, self.nquant), target.view(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
