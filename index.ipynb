{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llamass\n",
    "\n",
    "> A Light Loader for the [AMASS dataset][amass] to make downloading and training on it easier.\n",
    "\n",
    "I'm writing this to use in a project working with pose data. I wanted to be able to install it in colab notebooks and elsewhere easily. Hopefully it's also useful for other people but be aware this is research code so not necessarily reliable.\n",
    "\n",
    "[amass]: https://amass.is.tue.mpg.de/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Badges\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/llamass.svg)](https://badge.fury.io/py/llamass)\n",
    "\n",
    "\n",
    "![example workflow](https://github.com/gngdb/llamass/workflows/CI/badge.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License Agreement\n",
    "\n",
    "Before using the AMASS dataset I'm expected to sign up to the license agreeement [here][amass]. This package doesn't require any other code from MPI but visualization of pose data does, see below.\n",
    "\n",
    "### Install with pip\n",
    "\n",
    "Requirements are handled by pip during the install but in a new environment I would install [pytorch][]\n",
    "first to configure cuda as required for the system.\n",
    "\n",
    "`pip install llamass`\n",
    "\n",
    "### For Visualization\n",
    "\n",
    "To visualise this data [MPI][] packages are required and they ask you to sign up to abide by their license:\n",
    "\n",
    "* [Human Body Prior][hbp], licensed under the [SMPL-X project][smplx]\n",
    "* [Body Visualizer][body], licensed under the [SMPL-X project][smplx]\n",
    "\n",
    "To install on e.g. colab the following code snippet should work (I've fixed versions because these are the versions I've tested):\n",
    "\n",
    "```\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "!pip install pyrender\n",
    "!pip install mediapy\n",
    "!pip install human_body_prior@git+https://github.com/nghorbani/human_body_prior@7f0a4b3#egg=human_body_prior\n",
    "!pip install body_visualizer@git+https://github.com/nghorbani/body_visualizer@fe4e5e8#egg=body_visualizer\n",
    "```\n",
    "\n",
    "This relies on EGL being installed, which it is on colab but may require some configuration \n",
    "\n",
    "[mpi]: https://is.mpg.de/\n",
    "[hbp]: https://github.com/nghorbani/human_body_prior\n",
    "[pytorch]: https://pytorch.org/get-started/locally/\n",
    "[amassrepo]: https://github.com/nghorbani/amass/blob/master/notebooks/01-AMASS_Visualization.ipynb\n",
    "[body]: https://github.com/nghorbani/body_visualizer\n",
    "[smplx]: https://smpl-x.is.tue.mpg.de/\n",
    "[mesh]: https://github.com/MPI-IS/mesh\n",
    "[amass]: https://amass.is.tue.mpg.de/index.html\n",
    "[pytables]: https://www.pytables.org/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data\n",
    "\n",
    "The [AMASS website][amass] provides links to download the various parts of the AMASS dataset. Each is provided as a `.tar.bz2` and I had to download them from the website by hand. Save all of these in a folder somehwere.\n",
    "\n",
    "### Unpacking the data\n",
    "\n",
    "After installing `llamass`, it provides a console script to unpack the `tar.bz2` files downloaded from the [AMASS][] website:\n",
    "\n",
    "```\n",
    "fast_amass_unpack -n 4 --verify <dir with .tar.bz2 files> <dir to save unpacked data>\n",
    "```\n",
    "\n",
    "This will unpack the data in parallel in 4 jobs and provides a progress bar. The `--verify` flag will `md5sum` the directory the files are unpacked to and check it against what I found when I unpacked it. It'll also avoid unpacking tar files that have already been unpacked by looking for saved `.hash` files in the target directory. It's slower but more reliable and recovers from incomplete unpacking.\n",
    "\n",
    "Alternatively, this can be access in the library using the `llamass.core.unpack_body_models` function:\n",
    "\n",
    "[amass]: https://amass.is.tue.mpg.de/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "unpacked_directory = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmp7e_hb9we\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ebcd2e80ff47819ca3589b741d3755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import llamass.core\n",
    "\n",
    "llamass.core.unpack_body_models(\"sample_data/\", unpacked_directory, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Metadata\n",
    "\n",
    "I've processed the files to find out how many frames are in each numpy archive unpacked when `fast_amass_unpack` is run. By default, the first time the `AMASS` Dataset object is asked for it's `len` it will look for a file containing this information in the specified AMASS directory. If it doesn't find it, it will recompute it and that can take 5 minutes.\n",
    "\n",
    "Save 5 minutes by downloading it from this repository:\n",
    "\n",
    "```\n",
    "wget https://github.com/gngdb/llamass/raw/master/npz_file_lens.json.gz -P <dir to save unpacked data>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/val/test Split\n",
    "\n",
    "details of script for splits goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data\n",
    "\n",
    "Once the data is unpacked it can be loaded by a PyTorch DataLoader directly using the `llamass.core.AMASS` Dataset class.\n",
    "\n",
    "* `overlapping`: whether the clips of frames taken from each file should be allowed to overlap\n",
    "* `clip_length`: how long should clips from each file be?\n",
    "* `transform`: a transformation function apply to all fields\n",
    "\n",
    "It is an [IterableDataset][] so it **cannot be shuffled by the DataLoader**. If `shuffle=True` the DataLoader will hit an error. However, the `AMASS` class itself implements shuffling and it can be enabled using `shuffle=True` at initialisation.\n",
    "\n",
    "Also, in order to use more than one worker it is necessary to use the provided `worker_init_fn` in the DataLoader. This can also be accessed by using `llamass.core.IterableLoader` in place of `DataLoader`, and this is safer because using `DataLoader` without `worker_init_fn` will yield duplicate data when workers load from the same files.\n",
    "\n",
    "[iterabledataset]: https://pytorch.org/docs/stable/data.html#iterable-style-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "amass = llamass.core.AMASS(\n",
    "    unpacked_directory,\n",
    "    overlapping=False,\n",
    "    clip_length=1,\n",
    "    transform=torch.tensor,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses torch.Size([4, 1, 156])\n",
      "dmpls torch.Size([4, 1, 8])\n",
      "trans torch.Size([4, 1, 3])\n",
      "betas torch.Size([4, 1, 16])\n",
      "gender torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# these are equivalent\n",
    "amassloader = DataLoader(amass, batch_size=4, num_workers=2, worker_init_fn=llamass.core.worker_init_fn)\n",
    "amassloader = llamass.core.IterableLoader(amass, batch_size=4, num_workers=2)\n",
    "\n",
    "for data in amassloader:\n",
    "    for k in data:\n",
    "        print(k, data[k].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "shutil.rmtree(unpacked_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "To do:\n",
    "\n",
    "* ~~Add step in setup above to wget the file lengths~~\n",
    "* ~~Instructions on how to install the requirements for visualization~~\n",
    "* Augmentations pulled from original AMASS repo\n",
    "* Example train/test splits by unpacking different datasets to different locations\n",
    "* Update and link the colab notebook demonstrating visualization\n",
    "* ~~Disable CI?~~\n",
    "* How to use LMDB for accelerated loading\n",
    "    * Note about install: `!sudo apt-get install build-essential libcap-dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_tqdm.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
