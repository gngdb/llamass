{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Unpack and load the [AMASS][] dataset for training with a PyTorch iterator.\n",
    "\n",
    "To do:\n",
    "\n",
    "1. ~~Move ProgressParallel to a different notebook, something weird happens with it in here~~\n",
    "2. ~~Print info when recomputing npz lens~~\n",
    "3. ~~Information about file length must be split by directory, otherwise it's impossible to do train/val/test splits~~\n",
    "4. ~~Implement local cache shuffle with LMDB~~\n",
    "5. ~~Safe DataLoader class~~\n",
    "6. ~~Inspect and plot features, embed in notebook~~\n",
    "7. Refactor feature info and plots into features notebook\n",
    "8. Inspect bug to determine why dataset loading fails on colab on second try\n",
    "9. Description of features as being in \"exponential coordinates\" is wrong, they are angle-axis vectors\n",
    "\n",
    "[amass]: https://amass.is.tue.mpg.de/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack Tar Files\n",
    "\n",
    "> Console script to unpack all tar files found in a specified directory and put them in another directory, then create a symlink to be able to find the unpacked data later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checksum Directories\n",
    "\n",
    "> Checksum directories to only unpack tar files when target directory either doesn't exist or has been incorrectly unpacked.\n",
    "\n",
    "It would probably be sufficient to check if the target directory exists, but this is more thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://stackoverflow.com/a/54477583/6937913\n",
    "# function to evaluate the hash of an entire directory system to verify downloading and unpacking was correct\n",
    "import hashlib\n",
    "from _hashlib import HASH as Hash\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "def md5_update_from_file(filename: Union[str, Path], hash: Hash) -> Hash:\n",
    "    assert Path(filename).is_file()\n",
    "    with open(str(filename), \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash.update(chunk)\n",
    "    return hash\n",
    "\n",
    "\n",
    "def md5_file(filename: Union[str, Path]) -> str:\n",
    "    return str(md5_update_from_file(filename, hashlib.md5()).hexdigest())\n",
    "\n",
    "\n",
    "def md5_update_from_dir(directory: Union[str, Path], hash: Hash) -> Hash:\n",
    "    assert Path(directory).is_dir()\n",
    "    for path in sorted(Path(directory).iterdir(), key=lambda p: str(p).lower()):\n",
    "        hash.update(path.name.encode())\n",
    "        if path.is_file():\n",
    "            hash = md5_update_from_file(path, hash)\n",
    "        elif path.is_dir():\n",
    "            hash = md5_update_from_dir(path, hash)\n",
    "    return hash\n",
    "\n",
    "\n",
    "def md5_dir(directory: Union[str, Path]) -> str:\n",
    "    return str(md5_update_from_dir(directory, hashlib.md5()).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "hashes = {\n",
    "    \"ACCAD.tar.bz2\": {\n",
    "        \"unpacks_to\": \"ACCAD\",\n",
    "        \"hash\": \"193442a2ab66cb116932b8bce08ecb89\",\n",
    "    },\n",
    "    \"BMLhandball.tar.bz2\": {\n",
    "        \"unpacks_to\": \"BMLhandball\",\n",
    "        \"hash\": \"8947df17dd59d052ae618daf24ccace3\",\n",
    "    },\n",
    "    \"BMLmovi.tar.bz2\": {\n",
    "        \"unpacks_to\": \"BMLmovi\",\n",
    "        \"hash\": \"6dfb134273f284152aa2d0838d7529d5\",\n",
    "    },\n",
    "    \"CMU.tar.bz2\": {\"unpacks_to\": \"CMU\", \"hash\": \"f04bc3f37f3eafebfb12ba0cf706ca72\"},\n",
    "    \"DFaust67.tar.bz2\": {\n",
    "        \"unpacks_to\": \"DFaust_67\",\n",
    "        \"hash\": \"7e5f11ed897da72c5159ef3c747383b8\",\n",
    "    },\n",
    "    \"EKUT.tar.bz2\": {\"unpacks_to\": \"EKUT\", \"hash\": \"221ee4a27a03afd1808cbb11af067879\"},\n",
    "    \"HumanEva.tar.bz2\": {\n",
    "        \"unpacks_to\": \"HumanEva\",\n",
    "        \"hash\": \"ca781438b08caafd8a42b91cce905a03\",\n",
    "    },\n",
    "    \"KIT.tar.bz2\": {\"unpacks_to\": \"KIT\", \"hash\": \"3813500a3909f6ded1a1fffbd27ff35a\"},\n",
    "    \"MPIHDM05.tar.bz2\": {\n",
    "        \"unpacks_to\": \"MPI_HDM05\",\n",
    "        \"hash\": \"f76da8deb9e583c65c618d57fbad1be4\",\n",
    "    },\n",
    "    \"MPILimits.tar.bz2\": {\n",
    "        \"unpacks_to\": \"MPI_Limits\",\n",
    "        \"hash\": \"72398ec89ff8ac8550813686cdb07b00\",\n",
    "    },\n",
    "    \"MPImosh.tar.bz2\": {\n",
    "        \"unpacks_to\": \"MPI_mosh\",\n",
    "        \"hash\": \"a00019cac611816b7ac5b7e2035f3a8a\",\n",
    "    },\n",
    "    \"SFU.tar.bz2\": {\"unpacks_to\": \"SFU\", \"hash\": \"cb10b931509566c0a49d72456e0909e2\"},\n",
    "    \"SSMsynced.tar.bz2\": {\n",
    "        \"unpacks_to\": \"SSM_synced\",\n",
    "        \"hash\": \"7cc15af6bf95c34e481d58ed04587b58\",\n",
    "    },\n",
    "    \"TCDhandMocap.tar.bz2\": {\n",
    "        \"unpacks_to\": \"TCD_handMocap\",\n",
    "        \"hash\": \"c500aa07973bf33ac1587a521b7d66d3\",\n",
    "    },\n",
    "    \"TotalCapture.tar.bz2\": {\n",
    "        \"unpacks_to\": \"TotalCapture\",\n",
    "        \"hash\": \"b2c6833d3341816f4550799b460a1b27\",\n",
    "    },\n",
    "    \"Transitionsmocap.tar.bz2\": {\n",
    "        \"unpacks_to\": \"Transitions_mocap\",\n",
    "        \"hash\": \"705e8020405357d9d65d17580a6e9b39\",\n",
    "    },\n",
    "    \"EyesJapanDataset.tar.bz2\": {\n",
    "        \"unpacks_to\": \"Eyes_Japan_Dataset\",\n",
    "        \"hash\": \"d19fc19771cfdbe8efe2422719e5f3f1\",\n",
    "    },\n",
    "    \"BMLrub.tar.bz2\": {\n",
    "        \"unpacks_to\": \"BioMotionLab_NTroje\",\n",
    "        \"hash\": \"8b82ffa6c79d42a920f5dde1dcd087c3\",\n",
    "    },\n",
    "    \"DanceDB.tar.bz2\": {\n",
    "        \"unpacks_to\": \"DanceDB\",\n",
    "        \"hash\": \"9ce35953c4234489036ecb1c26ae38bc\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Unpacking with Joblib\n",
    "\n",
    "> Unpacks tar files in multiple jobs to speed up unpacking the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import json\n",
    "import argparse\n",
    "import functools\n",
    "import os\n",
    "from shutil import unpack_archive\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "from llamass.tqdm import ProgressParallel\n",
    "\n",
    "\n",
    "def lazy_unpack(tarpath, outdir):\n",
    "    # check if this has already been unpacked by looking for hash file\n",
    "    tarpath, outdir = Path(tarpath), Path(outdir)\n",
    "    unpacks_to = hashes[tarpath.name][\"unpacks_to\"]\n",
    "    hashpath = outdir / Path(unpacks_to + \".hash\")\n",
    "    # if the hash exists and it's correct then assume the directory is correctly unpacked\n",
    "    if hashpath.exists():\n",
    "        with open(hashpath) as f:\n",
    "            h = f.read()  # read hash\n",
    "        if h == hashes[tarpath.name][\"hash\"]:\n",
    "            return None\n",
    "    else:\n",
    "        # if there's no stored hash or it doesn't match, unpack the tar file\n",
    "        unpack_archive(tarpath, outdir)\n",
    "        # calculate the hash of the unpacked directory and check it's the same\n",
    "        h = md5_dir(outdir / unpacks_to)\n",
    "        _h = hashes[tarpath.name][\"hash\"]\n",
    "        assert h == _h, f\"Directory {outdir/unpacks_to} hash {h} != {_h}\"\n",
    "        # save the calculated hash\n",
    "        with open(hashpath, \"w\") as f:\n",
    "            f.write(h)\n",
    "\n",
    "\n",
    "def unpack_body_models(tardir, outdir, n_jobs=1, verify=False):\n",
    "    tar_root, _, tarfiles = [x for x in os.walk(tardir)][0]\n",
    "    tarfiles = [x for x in tarfiles if \"tar\" in x.split(\".\")]\n",
    "    tarpaths = [os.path.join(tar_root, tar) for tar in tarfiles]\n",
    "    for tarpath in tarpaths:\n",
    "        print(f\"{tarpath} extracting to {outdir}\")\n",
    "    unpack = lazy_unpack if verify else unpack_archive\n",
    "    ProgressParallel(n_jobs=n_jobs)(\n",
    "        (joblib.delayed(unpack)(tarpath, outdir) for tarpath in tarpaths),\n",
    "        total=len(tarpaths),\n",
    "    )\n",
    "\n",
    "\n",
    "def fast_amass_unpack():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Unpack all the body model tar files in a directory to a target directory\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"tardir\",\n",
    "        type=str,\n",
    "        help=\"Directory containing tar.bz2 body model files\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"outdir\",\n",
    "        type=str,\n",
    "        help=\"Output directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verify\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Verify the output by calculating a checksum, \"\n",
    "        \"ensures that each tar file will only be unpacked once.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-n\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Number of jobs to run the tar unpacking with\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    unpack_body_models(args.tardir, args.outdir, n_jobs=args.n, verify=args.verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test unpacking the sample data always yields the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmplytsq_ir\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10077ae5ae8b42f48761f319a0b1c364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tempfile\n",
    "import hashlib\n",
    "\n",
    "# https://stackoverflow.com/a/3431838/6937913\n",
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "md5sums = {\n",
    "    \"amass_sample.npz\": \"d0b546b3619c8579ade39e3a8ccdc4e2\",\n",
    "    \"dmpl_sample.npz\": \"576bb76b2a6328dc5c276c4150c466f0\",\n",
    "}\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    for r, d, f in os.walk(tmpdirname):\n",
    "        npz_files = [x for x in f if \"npz\" in x.split(\".\")]\n",
    "        npz_paths = [os.path.join(tmpdirname, r, x) for x in npz_files]\n",
    "    _md5sums = {os.path.split(fpath)[-1]: md5(fpath) for fpath in npz_paths}\n",
    "\n",
    "for k in md5sums:\n",
    "    assert md5sums[k] == _md5sums[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that `verify=True` works as expected. Can redefine `hashes` here for testing without breaking the exported library because this cell doesn't get exported by `nbdev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpkwy2g8_b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e45dc6ad9f490a9c900927a54b6ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpkwy2g8_b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aaf29893a5147eaa3ab6b30267ec251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "hashes = {\n",
    "    \"sample.tar.bz2\": {\n",
    "        \"unpacks_to\": \"sample\",\n",
    "        \"hash\": \"b5a86fe22ed2799d79101a532eb0ff27\",\n",
    "    }\n",
    "}\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    start = time.time()\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8, verify=True)\n",
    "    unpacking_time = time.time() - start\n",
    "    start = time.time()\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8, verify=True)\n",
    "    skip_time = time.time() - start\n",
    "    assert unpacking_time > skip_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Functions\n",
    "\n",
    "> Load the pose data directly from the `npz` files after unpacking.\n",
    "\n",
    "Based on the [AMASS tutorial notebooks][amass], I would like to iterate over the dataset using a PyTorch Dataloader.\n",
    "\n",
    "Steps to load:\n",
    "\n",
    "1. Index all of the `npz` files in the AMASS directory\n",
    "2. Iterate through all of them in sequence\n",
    "    1. Load the `npz` file\n",
    "    1. Cut out acceptable motion sequence in center of each file (typically middle 80% of motion sequence)\n",
    "    2. _Optionally_ shuffle the dataset\n",
    "    2. Iterate over this sequence along the first dimension\n",
    "3. When running with `num_workers > 0`, give each worker a different random set of `npz` files to load\n",
    "\n",
    "[amass]: https://github.com/nghorbani/amass/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpvnhncsxn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ed1bb9abfe469c9f403db242000433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpvnhncsxn/sample/subdir/amass_sample.npz\n",
      "   ['poses', 'gender', 'mocap_framerate', 'betas', 'marker_data', 'dmpls', 'marker_labels', 'trans']\n",
      "   [('poses', (601, 156)), ('gender', ()), ('mocap_framerate', ()), ('betas', (16,)), ('marker_data', (601, 85, 3)), ('dmpls', (601, 8)), ('marker_labels', (85,)), ('trans', (601, 3))]\n",
      "/tmp/tmpvnhncsxn/sample/subdir/dmpl_sample.npz\n",
      "   ['poses', 'gender', 'mocap_framerate', 'betas', 'marker_data', 'dmpls', 'marker_labels', 'trans']\n",
      "   [('poses', (235, 156)), ('gender', ()), ('mocap_framerate', ()), ('betas', (16,)), ('marker_data', (235, 67, 3)), ('dmpls', (235, 8)), ('marker_labels', (67,)), ('trans', (235, 3))]\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    for r, d, f in os.walk(tmpdirname):\n",
    "        npz_files = [x for x in f if \"npz\" in x.split(\".\")]\n",
    "        npz_paths = [os.path.join(tmpdirname, r, x) for x in npz_files]\n",
    "    for npz_path in npz_paths:\n",
    "        cdata = np.load(npz_path)\n",
    "        print(npz_path)\n",
    "        print(\"  \", [k for k in cdata.keys()])\n",
    "        print(\"  \", [(k, cdata[k].shape) for k in cdata.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def plot_file_sizes(unpacked_directory, bins):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "\n",
    "    def walk_npz_paths(npz_directory):\n",
    "        npz_paths = []\n",
    "        for r, d, f in os.walk(npz_directory):\n",
    "            npz_files = [\n",
    "                x for x in f if \"npz\" in x.split(\".\") and Path(x).name != \"shape.npz\"\n",
    "            ]\n",
    "            npz_paths += [os.path.join(npz_directory, r, x) for x in npz_files]\n",
    "        return tuple(npz_paths)\n",
    "\n",
    "    npz_paths = walk_npz_paths(unpacked_directory)\n",
    "\n",
    "    file_sizes = {}\n",
    "    for f in tqdm(npz_paths):\n",
    "        file_sizes[f] = os.stat(f).st_size\n",
    "\n",
    "    x = np.array(list(file_sizes.values()))\n",
    "    bins = np.logspace(np.log10(min(x)), np.log10(max(x)), bins)\n",
    "    plt.hist(x, bins=bins)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"File Size (bytes)\")\n",
    "    plt.title(\"Size of numpy archives in AMASS\")\n",
    "    plt.savefig(\"images/amass_file_sizes.png\")\n",
    "\n",
    "\n",
    "# uncomment and run on unpacked AMASS directory to regenerate plot\n",
    "# plot_file_sizes('/nobackup/gngdb/repos/amass/data', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AMASS dataset is composed of 14,096 `.npz` archives (at time of writing). The size of archives varies over two orders of magnitude, between 0.1MB and 10MB.\n",
    "\n",
    "![A histogram of the file sizes in AMASS](./images/amass_file_sizes.png \"AMASS File Sizes Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other statistics we might want to know:\n",
    "\n",
    "* Length of motion sequence in each of these files\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do the fields mean?\n",
    "\n",
    "![Screenshot quote from the AMASS paper](./images/amass-quote.png \"AMASS Quote\")\n",
    "\n",
    "AMASS `npz` files contain 5 fields (`'poses', 'gender', 'betas', 'dmpls', 'trans'`), what do they mean?\n",
    "\n",
    "* `poses` are [SMPLH][] vectors, which are a representation of pose based on [SMPL][] with additional information about the positions of the hands. What are SMPLH vectors composed of?\n",
    "    * 52 joints, each represented with 3 parameters, 22 for the body and 30 for the hands\n",
    "    * Encoded with 3 rotational degrees of freedom in exponential coordinates\n",
    "* `gender` is the reported gender of the actor (it's not clear if MPI has used their [gender classifier][gender] here)\n",
    "* `betas` are \"identity-dependent shape parameters\"\n",
    "* `dmpls` are soft tissue deformations described in the [original SMPL paper][smplpaper]\n",
    "* `trans` I think this is the $\\gamma$ 3D parameter representing the translation of the root coordinate system, it is required to describe the pose and should probably be concatenated to the pose vector as described in the [AMASS paper][amasspaper].\n",
    "\n",
    "[gender]: https://github.com/nghorbani/homogenus\n",
    "[SMPLH]: https://mano.is.tue.mpg.de/\n",
    "[SMPL]: https://smpl.is.tue.mpg.de/\n",
    "[smplpaper]: https://files.is.tue.mpg.de/black/papers/SMPL2015.pdf#page=12\n",
    "[amasspaper]: https://files.is.tue.mpg.de/black/papers/amass.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `npz` File Iterator\n",
    "\n",
    "> Iterates over all the paths of all the `npz` files in AMASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def npz_paths(npz_directory):\n",
    "    npz_paths = []\n",
    "    for r, d, f in os.walk(npz_directory):\n",
    "        for fname in f:\n",
    "            if \"npz\" == fname.split(\".\")[-1] and fname != \"shape.npz\":\n",
    "                yield os.path.join(npz_directory, r, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmp0im2kpwq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42f13d2539b4df39dfd4499da3948a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp0im2kpwq/sample/subdir/amass_sample.npz\n",
      "/tmp/tmp0im2kpwq/sample/subdir/dmpl_sample.npz\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    for npz_path in npz_paths(tmpdirname):\n",
    "        print(npz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# len([npz_path for npz_path in npz_paths('/nobackup/gngdb/repos/amass/data')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Dataset Size\n",
    "\n",
    "> A function to calculate dataset size, with the result stored in this package.\n",
    "\n",
    "The result of this calculation is stored in this package, the dataset loader will try to load this file or recreate it itself, so you can skip that step by copying it into the directory where you have unpacked the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def npz_len(npz_path):\n",
    "    cdata = np.load(npz_path)\n",
    "    h = md5_file(npz_path)\n",
    "    dirs = [hashes[h]['unpacks_to'] for h in hashes]\n",
    "    m = []\n",
    "    for p in Path(npz_path).parents:\n",
    "        m += [d for d in dirs if p.name == d]\n",
    "    assert len(m) == 1, f\"Subdir of {npz_path} contains two of {dirs}\"\n",
    "    subdir = m[0]\n",
    "    return subdir, h, cdata[\"poses\"].shape[0]\n",
    "\n",
    "def npz_lens(unpacked_directory, n_jobs):\n",
    "    paths = [p for p in npz_paths(unpacked_directory)]\n",
    "    return ProgressParallel(n_jobs=n_jobs)(\n",
    "        [joblib.delayed(npz_len)(npz_path) for npz_path in paths], total=len(paths)\n",
    "    )\n",
    "\n",
    "def save_lens(save_path, npz_file_lens):\n",
    "    with gzip.open(save_path, \"wt\") as f:\n",
    "        f.write(json.dumps(npz_file_lens))\n",
    "\n",
    "#npz_file_lens = npz_lens('/nobackup/gngdb/repos/amass/data', 10)\n",
    "#save_lens('npz_file_lens.json.gz', npz_file_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399K\tnpz_file_lens.json.gz\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs npz_file_lens.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viable Indexes\n",
    "\n",
    "For every `npz` file I need to pull out the viable indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def keep_slice(n, keep):\n",
    "    drop = (1.0 - keep) / 2.0\n",
    "    return slice(int(n * drop), int(n * keep + n * drop))\n",
    "\n",
    "\n",
    "def viable_slice(cdata, keep):\n",
    "    \"\"\"\n",
    "    Inspects a dictionary loaded from `.npz` numpy dumps\n",
    "    and creates a slice of the viable indexes.\n",
    "    args:\n",
    "\n",
    "        - `cdata`: dictionary containing keys:\n",
    "            ['poses', 'gender', 'mocap_framerate', 'betas',\n",
    "             'marker_data', 'dmpls', 'marker_labels', 'trans']\n",
    "        - `keep`: ratio of the file to keep, between zero and 1.,\n",
    "            drops leading and trailing ends of the arrays\n",
    "\n",
    "    returns:\n",
    "\n",
    "        - viable: slice that can access frames in the arrays:\n",
    "            cdata['poses'], cdata['marker_data'], cdata['dmpls'], cdata['trans']\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        keep > 0.0 and keep <= 1.0\n",
    "    ), \"Proportion of array to keep must be between zero and one\"\n",
    "    n = cdata[\"poses\"].shape[0]\n",
    "    return keep_slice(n, keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpxvqbce40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5a2a7600914e558c17da73d2b04368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpxvqbce40/sample/subdir/amass_sample.npz\n",
      "   slice(60, 540, None)\n",
      "/tmp/tmpxvqbce40/sample/subdir/dmpl_sample.npz\n",
      "   slice(23, 211, None)\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    for npz_path in npz_paths(tmpdirname):\n",
    "        cdata = np.load(npz_path)\n",
    "        print(npz_path)\n",
    "        print(\"  \", viable_slice(cdata, 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `npz` Contents Iterator\n",
    "\n",
    "> Loads an `.npz` file and iterates over the examples within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def npz_contents(\n",
    "    npz_path,\n",
    "    clip_length,\n",
    "    overlapping,\n",
    "    keep=0.8,\n",
    "    keys=(\"poses\", \"dmpls\", \"trans\", \"betas\", \"gender\"),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "):\n",
    "    # cache this because we will often be accessing the same file multiple times\n",
    "    cdata = np.load(npz_path)\n",
    "\n",
    "    # slice of viable indices\n",
    "    viable = viable_slice(cdata, keep)\n",
    "\n",
    "    # slice iterator\n",
    "    def clip_slices(viable, clip_length, overlapping):\n",
    "        i = 0\n",
    "        step = 1 if overlapping else clip_length\n",
    "        for i in range(viable.start, viable.stop, step):\n",
    "            if i + clip_length < viable.stop:\n",
    "                yield slice(i, i + clip_length)\n",
    "\n",
    "    # buffer the iterator and shuffle here, when implementing that\n",
    "    buf_clip_slices = [s for s in clip_slices(viable, clip_length, overlapping)]\n",
    "    if shuffle:\n",
    "        seed = seed if seed else random.randint(1e6)\n",
    "        random.Random(seed).shuffle(buf_clip_slices)\n",
    "\n",
    "    # iterate over slices\n",
    "    for s in buf_clip_slices:\n",
    "        data = {}\n",
    "        # unpack and enforce data type\n",
    "        to_load = [k for k in (\"poses\", \"dmpls\", \"trans\") if k in keys]\n",
    "        for k in to_load:\n",
    "            data[k] = cdata[k][s].astype(np.float32)\n",
    "        if \"betas\" in keys:\n",
    "            r = s.stop - s.start\n",
    "            data[\"betas\"] = np.repeat(\n",
    "                cdata[\"betas\"][np.newaxis].astype(np.float32), repeats=r, axis=0\n",
    "            )\n",
    "        if \"gender\" in keys:\n",
    "\n",
    "            def gender_to_int(g):\n",
    "                # casting gender to integer will raise a warning in future\n",
    "                g = str(g.astype(str))\n",
    "                return {\"male\": -1, \"neutral\": 0, \"female\": 1}[g]\n",
    "\n",
    "            data[\"gender\"] = np.array(\n",
    "                [gender_to_int(cdata[\"gender\"]) for _ in range(s.start, s.stop)]\n",
    "            )\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmp5osu4pzt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e635168176024105922dba29d158276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('poses', (1, 156)), ('dmpls', (1, 8)), ('trans', (1, 3)), ('betas', (1, 16)), ('gender', (1,))]\n",
      "[('poses', (1, 156)), ('dmpls', (1, 8)), ('trans', (1, 3)), ('betas', (1, 16)), ('gender', (1,))]\n",
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpgb3_7__k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a95b5abd974336b9246cd98eac6aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('poses', (3, 156)), ('dmpls', (3, 8)), ('trans', (3, 3)), ('betas', (3, 16)), ('gender', (3,))]\n",
      "[('poses', (3, 156)), ('dmpls', (3, 8)), ('trans', (3, 3)), ('betas', (3, 16)), ('gender', (3,))]\n",
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpnnkyr2gb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca1da3e13b8407ba4ac7451e4a78977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('poses', (3, 156)), ('dmpls', (3, 8)), ('trans', (3, 3)), ('betas', (3, 16)), ('gender', (3,))]\n",
      "[('poses', (3, 156)), ('dmpls', (3, 8)), ('trans', (3, 3)), ('betas', (3, 16)), ('gender', (3,))]\n"
     ]
    }
   ],
   "source": [
    "def test_load_npz(clip_length, overlapping):\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "        for npz_path in npz_paths(tmpdirname):\n",
    "            for data in npz_contents(npz_path, clip_length, overlapping):\n",
    "                print([(k, data[k].shape) for k in data])\n",
    "                for k in data:\n",
    "                    assert data[k].shape[0] == clip_length\n",
    "                break\n",
    "\n",
    "\n",
    "test_load_npz(1, False)\n",
    "test_load_npz(3, False)\n",
    "test_load_npz(3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Dataset Class\n",
    "\n",
    "> An iterable style PyTorch Dataset class to iterate over all of the `.npz` files storing motion sequences in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/nobackup/gngdb/repos/amass/data/val'),\n",
       " Path('/nobackup/gngdb/repos/amass/data/test'),\n",
       " Path('/nobackup/gngdb/repos/amass/data/train')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in Path('/nobackup/gngdb/repos/amass/data').glob('*') if p.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class AMASS(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        amass_location,\n",
    "        clip_length,\n",
    "        overlapping,\n",
    "        keep=0.8,\n",
    "        transform=None,\n",
    "        data_keys=(\"poses\", \"dmpls\", \"trans\", \"betas\", \"gender\"),\n",
    "        file_list_seed=0,\n",
    "        shuffle=False,\n",
    "        seed=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        self.data_keys = data_keys\n",
    "        self.amass_location = amass_location\n",
    "        # these should be shuffled but pull shuffle argument out of dataloader worker arguments\n",
    "        self._npz_paths = [npz_path for npz_path in npz_paths(amass_location)]\n",
    "        random.Random(file_list_seed).shuffle(self._npz_paths)\n",
    "        self._npz_paths = tuple(self._npz_paths)\n",
    "        self.npz_paths = self._npz_paths\n",
    "        self.clip_length = clip_length\n",
    "        self.overlapping = overlapping\n",
    "        self.keep = keep\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed if seed else random.randint(0, 1e6)\n",
    "\n",
    "    def infer_len(self, n_jobs=4):\n",
    "        # uses known dimensions of the npz files in the AMASS dataset to infer the length\n",
    "        # with clip_length and overlapping settings stored\n",
    "        lenfile = Path(self.amass_location) / Path(\"npz_file_lens.json.gz\")\n",
    "        # try to load file\n",
    "        if lenfile.exists():\n",
    "            with gzip.open(lenfile, \"rt\") as f:\n",
    "                self.npz_lens = json.load(f)\n",
    "                def filter_lens(npz_lens):\n",
    "                    # filter out file length information to only existing dirs\n",
    "                    datasets = [p.name for p in Path(self.amass_location).glob('*') if p.is_dir()]\n",
    "                    return [(p, h, l) for p, h, l in npz_lens\n",
    "                            if p in datasets]\n",
    "                self.npz_lens = filter_lens(self.npz_lens)\n",
    "        else:  # if it's not there, recompute it and create the file\n",
    "            print(f'Inspecting {len(self.npz_paths)} files to determine dataset length'\n",
    "                  f', saving the result to {lenfile}')\n",
    "            self.npz_lens = npz_lens(self.amass_location, n_jobs)\n",
    "            save_lens(lenfile, self.npz_lens)\n",
    "\n",
    "        # using stored lengths to infer the total dataset length\n",
    "        def lenslice(s):\n",
    "            if self.overlapping:\n",
    "                return (s.stop - s.start) - (self.clip_length - 1)\n",
    "            else:\n",
    "                return math.floor((s.stop - s.start) / self.clip_length)\n",
    "\n",
    "        N = 0\n",
    "        for p, h, l in self.npz_lens:\n",
    "            s = keep_slice(l, keep=self.keep)\n",
    "            N += lenslice(s)\n",
    "\n",
    "        return N\n",
    "\n",
    "    def __len__(self):\n",
    "        if hasattr(self, \"N\"):\n",
    "            return self.N\n",
    "        else:\n",
    "            self.N = self.infer_len()\n",
    "            return self.N\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.npz_paths = list(self.npz_paths)\n",
    "            random.Random(self.seed).shuffle(self.npz_paths)\n",
    "        for npz_path in self.npz_paths:\n",
    "            for data in npz_contents(\n",
    "                npz_path,\n",
    "                self.clip_length,\n",
    "                self.overlapping,\n",
    "                keep=self.keep,\n",
    "                shuffle=self.shuffle,\n",
    "                seed=self.seed,\n",
    "            ):\n",
    "                self.seed += 1  # increment to vary shuffle over files\n",
    "                yield {k: self.transform(data[k]) for k in data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test I can load some data with this Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmppnb6v8k7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08561a4c19d44405b10cb104b8a7274b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses torch.Size([1, 156])\n",
      "dmpls torch.Size([1, 8])\n",
      "trans torch.Size([1, 3])\n",
      "betas torch.Size([1, 16])\n",
      "gender torch.Size([1])\n",
      "Inspecting 2 files to determine dataset length, saving the result to /tmp/tmppnb6v8k7/npz_file_lens.json.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c2fdbbaecb479ba2946e9e3333baa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    amass = AMASS(tmpdirname, overlapping=False, clip_length=1, transform=torch.tensor)\n",
    "    for data in amass:\n",
    "        for k in data:\n",
    "            print(k, data[k].shape)\n",
    "            assert type(data[k]) is torch.Tensor\n",
    "        break\n",
    "    print(len(amass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it works in a DataLoader to make batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpuw80qtwq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b56b5fc192d45c3a45bba807166a67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses torch.Size([4, 1, 156])\n",
      "dmpls torch.Size([4, 1, 8])\n",
      "trans torch.Size([4, 1, 3])\n",
      "betas torch.Size([4, 1, 16])\n",
      "gender torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    amass = AMASS(tmpdirname, overlapping=False, clip_length=1, transform=torch.tensor)\n",
    "    amasstrain = DataLoader(amass, batch_size=4)\n",
    "    for i, data in enumerate(amasstrain):\n",
    "        for k in data:\n",
    "            print(k, data[k].shape)\n",
    "        assert data[\"poses\"].size(0) == 4, f'{data[\"poses\"].size()}'\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-process Data Loading\n",
    "\n",
    "> To work with `num_workers > 0` I'm going to pass a different set of `npz` files to each worker using a `worker_init_fn`.\n",
    "\n",
    "The following `worker_init_fn` must **always** be used when using `num_workers > 0` or data will be duplicated. To simplify I am providing a DataLoader class that bakes this `worker_init_fn` in when `num_workers > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "\n",
    "    # slice up dataset among workers\n",
    "    dataset = worker_info.dataset\n",
    "    overall_npz_paths = dataset._npz_paths\n",
    "    step = int(len(overall_npz_paths) / float(worker_info.num_workers))\n",
    "    n = len(overall_npz_paths)\n",
    "    assert n >= worker_info.num_workers, (\n",
    "        \"Every worker must get at least one file:\" f\" {worker_info.num_workers} > {n}\"\n",
    "    )\n",
    "    start, stop = 0, n\n",
    "    for worker_idx, i in enumerate(range(start, stop, step)):\n",
    "        if worker_idx == worker_info.id:\n",
    "            worker_slice = slice(i, min(i + step, n + 1))\n",
    "    dataset.npz_paths = overall_npz_paths[worker_slice]\n",
    "\n",
    "    # set each workers seed\n",
    "    dataset.seed = dataset.seed + worker_info.seed\n",
    "\n",
    "class IterableLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs['worker_init_fn'] = worker_init_fn\n",
    "        super().__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpgrlwdbt0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8aad5ca37a4d77bebb12c0653e4da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses torch.Size([4, 1, 156])\n",
      "dmpls torch.Size([4, 1, 8])\n",
      "trans torch.Size([4, 1, 3])\n",
      "betas torch.Size([4, 1, 16])\n",
      "gender torch.Size([4, 1])\n",
      "poses torch.Size([4, 1, 156])\n",
      "dmpls torch.Size([4, 1, 8])\n",
      "trans torch.Size([4, 1, 3])\n",
      "betas torch.Size([4, 1, 16])\n",
      "gender torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "def test_dataloader():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "        amass = AMASS(\n",
    "            tmpdirname, overlapping=False, clip_length=1, transform=torch.tensor\n",
    "        )\n",
    "        amasstrain = DataLoader(\n",
    "            amass, batch_size=4, worker_init_fn=worker_init_fn, num_workers=2\n",
    "        )\n",
    "        for i, data in enumerate(amasstrain):\n",
    "            for k in data:\n",
    "                print(k, data[k].shape)\n",
    "            assert data[\"poses\"].size(0) == 4, f'{data[\"poses\"].size()}'\n",
    "            break\n",
    "        amasstrain = IterableLoader(\n",
    "            amass, batch_size=4, num_workers=2\n",
    "        )\n",
    "        for i, data in enumerate(amasstrain):\n",
    "            for k in data:\n",
    "                print(k, data[k].shape)\n",
    "            assert data[\"poses\"].size(0) == 4, f'{data[\"poses\"].size()}'\n",
    "            break\n",
    "\n",
    "test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_runtime(unpacked_dir, batch_size, num_workers):\n",
    "    amass = AMASS(\n",
    "        unpacked_dir, overlapping=False, clip_length=1, transform=torch.tensor, seed=0\n",
    "    )\n",
    "    amasstrain = DataLoader(\n",
    "        amass, batch_size=batch_size, worker_init_fn=worker_init_fn, num_workers=num_workers\n",
    "    )\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    for data in tqdm(amasstrain):\n",
    "        i += 1\n",
    "        if i > 100:\n",
    "            break\n",
    "    elapsed = time.time() - start\n",
    "    total_hours = ((elapsed / i) * len(amasstrain)) / (60 ** 2)\n",
    "    return elapsed, elapsed / i, total_hours\n",
    "\n",
    "\n",
    "# test_runtime('/nobackup/gngdb/repos/amass/data', 256, 8)\n",
    "# test_runtime('/scratch/gobi1/gngdb/amass', 256, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough results from testing runtime on full dataset on my workstation:\n",
    "\n",
    "* Batch size 32:\n",
    "    * 0: 260ms/batch, 35 hours per epoch\n",
    "    * 2: 91ms/batch, 12 hours per epoch\n",
    "    * 4: 58ms/batch, 7 hours 54 minutes per epoch\n",
    "    * 8: 29ms/batch, 4 hours per epoch\n",
    "    * 12 (number of cores): 3 hours 45 minutes per epoch\n",
    "* Batch size 256:\n",
    "    * 0: 910ms/batch, 16 hours per epoch\n",
    "    * 2: 816ms/batch, 14 hours per epoch\n",
    "    * 4: 457ms/batch, 8 hours per epoch\n",
    "    * 8: 235ms/batch, 4 hours per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling\n",
    "\n",
    "PyTorch DataLoaders don't support shuffling IterableDataset because it's assuming the data is coming in as an IID stream. For this problem, this means the shuffling has to be implemented elsewhere.\n",
    "\n",
    "There are two parts to shuffle:\n",
    "\n",
    "* The indexes accessing the arrays in each file\n",
    "* The list of files to access\n",
    "\n",
    "The first is easy and can be an option to the iterator over each file. It doesn't affect how each worker operates because no two workers should ever touch the same file.\n",
    "\n",
    "The second is more difficult because each worker has a different list of files. Also, it's important that the order of the global list of files be random, because some files are larger than others and the randomness is to ensure that each worker has approximately the same number of examples in the files it has received. However, every worker initialises a separate dataset, so each dataset has to have access to the same list of files. I think the best way to ensure this at this point is to use a shared random seed to shuffle the list of files at initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpcgga_kh9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f064bb8d9dd410489a63c2846d696b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpgoo3jnx4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3567931266e54fbb85f511971a3a2f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmp4g21s285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598b1a07bd5c493aa8047f446539fa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_shuffling(num_workers):\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "        amass = AMASS(\n",
    "            tmpdirname,\n",
    "            overlapping=False,\n",
    "            clip_length=1,\n",
    "            transform=torch.tensor,\n",
    "            shuffle=True,\n",
    "            seed=0,\n",
    "        )\n",
    "        amasstrain = DataLoader(\n",
    "            amass, batch_size=4, worker_init_fn=worker_init_fn, num_workers=num_workers\n",
    "        )\n",
    "        for i, data in enumerate(amasstrain):\n",
    "            _data = data[\"poses\"]\n",
    "            break\n",
    "        # second epoch shouldn't produce the same minibatch\n",
    "        for i, data in enumerate(amasstrain):\n",
    "            data = data[\"poses\"]\n",
    "            data, _data = data.numpy(), _data.numpy()\n",
    "            assert not np.allclose(data, _data)\n",
    "            break\n",
    "\n",
    "\n",
    "for num_workers in range(3):\n",
    "    test_shuffling(num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test Splits\n",
    "\n",
    "> Console utility to split directories in a standard way\n",
    "\n",
    "The original preprocessing script splits directories [the following way](https://github.com/nghorbani/amass/blob/master/src/amass/data/prepare_data.py#L235-L239):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_amass_splits = {\n",
    "    'val' : ['HumanEva', 'MPI_HDM05', 'SFU', 'MPI_mosh'],\n",
    "    'test': ['Transitions_mocap', 'SSM_synced'],\n",
    "    'train': ['CMU', 'MPI_Limits', 'TotalCapture', 'Eyes_Japan_Dataset', 'KIT', 'BML', 'EKUT', 'TCD_handMocap', 'ACCAD']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't allocated all the datasets composing AMASS to a split:\n",
    "\n",
    "```\n",
    "Datasets not allocated to a split: {'BMLmovi', 'BioMotionLab_NTroje', 'DanceDB', 'BMLhandball', 'DFaust_67'}\n",
    "```\n",
    "\n",
    "Obtained by evaluating the following cell on an unpacked directory of AMASS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unallocated_splits(unpacked_dir):\n",
    "    data_path = Path(unpacked_dir)\n",
    "    all_subdirs = {f.name for f in data_path.iterdir() if f.is_dir()}\n",
    "    unallocated = all_subdirs - {d for k in amass_splits for d in amass_splits[k]}\n",
    "    print(f'Datasets not allocated to a split: {unallocated}')\n",
    "# unallocated_splits('/nobackup/gngdb/repos/amass/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to include all the newer datasets in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "amass_splits = {\n",
    "    'val' : ['HumanEva', 'MPI_HDM05', 'SFU', 'MPI_mosh'],\n",
    "    'test': ['Transitions_mocap', 'SSM_synced'],\n",
    "    'train': ['CMU', 'MPI_Limits', 'TotalCapture', 'Eyes_Japan_Dataset',\n",
    "              'KIT', 'BML', 'EKUT', 'TCD_handMocap', 'ACCAD',\n",
    "              'BMLmovi', 'BioMotionLab_NTroje', 'DanceDB', 'BMLhandball', 'DFaust_67']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions move the directories into subdirectories that define the splits and undo this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def move_dirs_into_splits(amass_loc, splits, undo=False):\n",
    "    amass_loc = Path(amass_loc)\n",
    "    for k in amass_splits:\n",
    "        split_dir = amass_loc / Path(k)\n",
    "        if not split_dir.exists():\n",
    "            os.mkdir(split_dir)\n",
    "        for d in amass_splits[k]:\n",
    "            d = Path(d)\n",
    "            t = split_dir/d\n",
    "            f = amass_loc/d\n",
    "            try:\n",
    "                if undo:\n",
    "                    os.rename(t, f)\n",
    "                else:\n",
    "                    os.rename(f, t)\n",
    "            except FileNotFoundError:\n",
    "                warnings.warn(f'Could not find {d} for {k} split')\n",
    "    \n",
    "move_dirs_out_of_splits = functools.partial(move_dirs_into_splits, undo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def console_split_dirs():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Split AMASS Dataset subdirs into train/val/test\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"amassloc\",\n",
    "        type=str,\n",
    "        help=\"Location where AMASS has been unpacked\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--undo\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Undo move into subdirectories, put them all back in the root AMASS location\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    move_dirs_into_splits(args.amassloc, amass_splits, undo=args.undo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMDB with DataFlow\n",
    "\n",
    "> Save the dataset to an lmdb database to enable the fastest possible load times\n",
    "\n",
    "Using the `AMASS` dataset class as a way to iterate over the entire dataset, I can save the dataset to a single LMDB Database and then load it much more cheaply in a training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import dataflow as td\n",
    "\n",
    "\n",
    "def write_to_lmdb(dataset, batch_size, num_workers=0, prefetch_factor=4):\n",
    "    overlapping = 'overlapping' if dataset.overlapping else 'separated'\n",
    "    db_filename = f'amass-{dataset.clip_length}-{overlapping}.lmdb'\n",
    "    db_loc = os.path.join(dataset.amass_location, db_filename)\n",
    "    def collate_fn(data):\n",
    "        return data\n",
    "    amassloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size, \n",
    "        worker_init_fn=worker_init_fn, \n",
    "        num_workers=num_workers, \n",
    "        collate_fn=collate_fn,\n",
    "        prefetch_factor=prefetch_factor if num_workers > 0 else 2\n",
    "        )\n",
    "    class IterLoader():\n",
    "        def __len__(self):\n",
    "            return len(dataset)\n",
    "        def __iter__(self):\n",
    "            for collated_data in amassloader:\n",
    "                for data in collated_data:\n",
    "                    yield data\n",
    "    df = td.DataFromGenerator(IterLoader())\n",
    "    # df = MultiProcessRunnerZMQ(df, num_proc=num_proc)\n",
    "    td.LMDBSerializer.save(df, db_loc)\n",
    "    return db_loc\n",
    "\n",
    "class AMASSdb(IterableDataset):\n",
    "    def __init__(self, db_loc, transform, shuffle=False, num_workers=0, cache=None):\n",
    "        self.lmdb = td.LMDBData(db_loc, shuffle=False)\n",
    "        if shuffle:\n",
    "            assert cache is not None, 'Sequential reads must be cached to shuffle'\n",
    "            self.ds = td.LocallyShuffleData(self.lmdb, cache)\n",
    "        else:\n",
    "            self.ds = self.lmdb\n",
    "        # data loading function\n",
    "        def f(x):\n",
    "            data = td.LMDBSerializer._deserialize_lmdb(x)\n",
    "            return transform(data)\n",
    "        \n",
    "        if num_workers > 0:\n",
    "            # unsure which of these is preferred\n",
    "            # self.ds = td.MultiProcessMapDataZMQ(self.ds, num_proc=num_workers, map_func=f)\n",
    "            self.ds = td.MultiThreadMapData(self.ds, num_thread=num_workers, map_func=f)\n",
    "        else:\n",
    "            self.ds = td.MapData(self.ds, f)\n",
    "        \n",
    "        # store number of workers\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        # reset the state and prepare an iterator\n",
    "        self.ds.reset_state()\n",
    "        self.ds_iter = iter(self.ds)\n",
    "        self.N = self.ds.size()\n",
    "        self.i = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __next__(self):\n",
    "        if (self.i + 1) == self.N:\n",
    "            raise StopIteration\n",
    "        data = next(self.ds_iter)\n",
    "        self.i += 1\n",
    "        return data\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        return self\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb):\n",
    "        self.lmdb._close_lmdb(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmpagi8eyte\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2fbc339089416bb35b694b880dd0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting 2 files to determine dataset length, saving the result to /tmp/tmpagi8eyte/npz_file_lens.json.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c24c48d81c4c449c7745f0c0bd35ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfa8fb7b13e42d188bf8d8c32a75af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1008 19:04:24 @serialize.py:103]\u001b[0m Flushing database ...\n",
      "os.stat_result(st_mode=33188, st_ino=1305613, st_dev=2053, st_nlink=1, st_uid=10521, st_gid=10536, st_size=1409024, st_atime=1633734262, st_mtime=1633734264, st_ctime=1633734264)\n",
      "\u001b[32m[1008 19:04:24 @format.py:91]\u001b[0m Found 666 entries in /tmp/tmpagi8eyte/amass-1-separated.lmdb\n",
      "[('poses', (1, 156)), ('dmpls', (1, 8)), ('trans', (1, 3)), ('betas', (1, 16)), ('gender', (1,))]\n",
      "[('poses', (1, 156)), ('dmpls', (1, 8)), ('trans', (1, 3)), ('betas', (1, 16)), ('gender', (1,))]\n",
      "poses torch.Size([4, 1, 156])\n",
      "dmpls torch.Size([4, 1, 8])\n",
      "trans torch.Size([4, 1, 3])\n",
      "betas torch.Size([4, 1, 16])\n",
      "gender torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    amass = AMASS(tmpdirname, overlapping=False, clip_length=1, transform=lambda x: x)\n",
    "    db_loc = write_to_lmdb(amass, 4, 0)\n",
    "    print(os.stat(db_loc))\n",
    "    amassdb = AMASSdb(db_loc, transform=lambda x: x, num_workers=1)\n",
    "    for data in amassdb:\n",
    "        break\n",
    "    print([(k, data[k].shape) for k in data])\n",
    "    for _data in amass:\n",
    "        break\n",
    "    print([(k, _data[k].shape) for k in _data])\n",
    "    assert all(np.allclose(data[k], _data[k]) for k in data)\n",
    "    amasstrain = DataLoader(amassdb, batch_size=4)\n",
    "    for i, data in enumerate(amasstrain):\n",
    "        for k in data:\n",
    "            print(k, data[k].shape)\n",
    "        assert data[\"poses\"].size(0) == 4, f'{data[\"poses\"].size()}'\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data/sample.tar.bz2 extracting to /tmp/tmp090vmjrf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612d1ef96fff4a12a0eefa2b2e939b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting 2 files to determine dataset length, saving the result to /tmp/tmp090vmjrf/npz_file_lens.json.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fa2f82742f48a3b43379dc87b8ce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b670d5933f4b749d19ca0237c746ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1008 19:04:26 @serialize.py:103]\u001b[0m Flushing database ...\n",
      "\u001b[32m[1008 19:04:26 @format.py:91]\u001b[0m Found 666 entries in /tmp/tmp090vmjrf/amass-1-separated.lmdb\n",
      "\u001b[32m[1008 19:04:26 @format.py:91]\u001b[0m Found 666 entries in /tmp/tmp090vmjrf/amass-1-separated.lmdb\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    unpack_body_models(\"sample_data/\", tmpdirname, 8)\n",
    "    amass = AMASS(tmpdirname, overlapping=False, clip_length=1, transform=lambda x: x)\n",
    "    db_loc = write_to_lmdb(amass, 4, 0)\n",
    "    amassdb = AMASSdb(db_loc, transform=lambda x: x, num_workers=1)\n",
    "    for data in DataLoader(amassdb, batch_size=4):\n",
    "        break\n",
    "    amassdb = AMASSdb(db_loc, transform=lambda x: x, shuffle=True, cache=10)\n",
    "    for _data in DataLoader(amassdb, batch_size=4):\n",
    "        break\n",
    "    assert not np.allclose(data['poses'], _data['poses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Console Script\n",
    "\n",
    "> Write the Dataset to an LMDB database with specified `clip_length` and `overlapping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def amass_to_lmdb(unpacked_dir, batch_size, num_workers, overlapping=False, clip_length=1):\n",
    "    amass = AMASS(\n",
    "        unpacked_dir, overlapping=overlapping, clip_length=clip_length,\n",
    "        transform=lambda x: x, seed=0, data_keys=('poses', 'trans')\n",
    "    )\n",
    "    db_loc = write_to_lmdb(amass, batch_size, num_workers)\n",
    "\n",
    "# amass_to_lmdb('/nobackup/gngdb/repos/amass/data', 256, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def console_amass_to_lmdb():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Process AMASS into an LMDB Database for faster loading\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"amassloc\",\n",
    "        type=str,\n",
    "        help=\"Location where AMASS has been unpacked\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"clip_length\",\n",
    "        type=int,\n",
    "        help=\"Length of motion subsequences to save as individual examples\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"num_workers\",\n",
    "        type=int,\n",
    "        help=\"Number of worker processes to use when loading data, does not affect resulting LMDB\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        default=256,\n",
    "        help=\"Batch size used to load examples from the numpy archives, does not affect resulting LMDB\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overlapping\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether motion subsequences should overlap, may increase LMDB size massively\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    amass_to_lmdb(\n",
    "        args.amassloc,\n",
    "        args.batch_size,\n",
    "        args.num_workers,\n",
    "        overlapping=args.overlapping,\n",
    "        clip_length=args.clip_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_tqdm.ipynb.\n",
      "Converted 02_features.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
